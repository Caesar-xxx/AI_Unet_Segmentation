{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af11f5f-7677-41ca-a9d8-7d1851ea9588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试训练好的模型\n",
    "# 1.从权重中加载模型\n",
    "# 2.对test_data进行测试，把标注和预测的结果作对比\n",
    "# 3.生成动画\n",
    "# 4.预测一下imagesTs下的文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89e8395-fdb7-43df-88b9-64c28e1376c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69de61f-3e24-4fb9-a8f1-764f2b9fc7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义两次卷积操作\n",
    "class ConvBlock(torch.nn.Module):\n",
    "    def __init__(self,in_channels,out_channels):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.step = torch.nn.Sequential(\n",
    "            # 第一次卷积\n",
    "            torch.nn.Conv2d(in_channels=in_channels,out_channels=out_channels,kernel_size=3,padding=1,stride=1),\n",
    "            # ReLU\n",
    "            torch.nn.ReLU(),\n",
    "            # 第二次卷积\n",
    "            torch.nn.Conv2d(in_channels=out_channels,out_channels=out_channels,kernel_size=3,padding=1,stride=1),\n",
    "            # ReLU\n",
    "            torch.nn.ReLU()\n",
    "        )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        \n",
    "        return self.step(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e03d8b-faa8-471d-a56d-4eb01dc8d47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 定义左侧编码器的操作\n",
    "        self.layer1 = ConvBlock(1,64)\n",
    "        self.layer2 = ConvBlock(64,128)\n",
    "        self.layer3 = ConvBlock(128,256)\n",
    "        self.layer4 = ConvBlock(256,512)\n",
    "        \n",
    "        # 定义右侧解码器的操作\n",
    "        self.layer5 = ConvBlock(256+512,256)\n",
    "        self.layer6 = ConvBlock(128+256,128)\n",
    "        self.layer7 = ConvBlock(64+128,64)\n",
    "        \n",
    "        #最后一个卷积\n",
    "        self.layer8  = torch.nn.Conv2d(in_channels=64,out_channels=1,kernel_size=1,padding=0,stride=1)\n",
    "        \n",
    "        # 定一些其他操作\n",
    "        # 池化\n",
    "        self.maxpool = torch.nn.MaxPool2d(kernel_size=2)\n",
    "        #上采样\n",
    "        self.upsample = torch.nn.Upsample(scale_factor=2,mode='bilinear')\n",
    "        # sigmoid\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "    \n",
    "    def forward(self,x):\n",
    "        # 对输入数据进行处理\n",
    "        \n",
    "        # 定义下采样部分\n",
    "        \n",
    "        # input:1X256x256, output: 64x256x256\n",
    "        x1 = self.layer1(x)\n",
    "        # input:64x256x256, output: 64 x 128 x 128\n",
    "        x1_p = self.maxpool(x1)\n",
    "        \n",
    "        # input:  64 x 128 x 128 , output: 128 x 128 x 128\n",
    "        x2 = self.layer2(x1_p)\n",
    "        # input:128 x 128 x 128 , output: 128 x 64 x 64\n",
    "        x2_p = self.maxpool(x2)\n",
    "        \n",
    "        # input: 128 x 64 x 64, output: 256 x 64 x 64\n",
    "        x3 = self.layer3(x2_p)\n",
    "        #input:256 x 64 x 64, output: 256 x 32 x 32\n",
    "        x3_p = self.maxpool(x3)\n",
    "        \n",
    "        #input: 256 x 32 x 32, output: 512 x 32 x 32\n",
    "        x4 = self.layer4(x3_p)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # 定义上采样\n",
    "        # input: 512 x 32 x 32，output: 512 x 64 x 64\n",
    "        x5 = self.upsample(x4)\n",
    "        # 拼接,output: 768x 64 x 64\n",
    "        x5 = torch.cat([x5,x3],dim=1)\n",
    "        # input: 768x 64 x 64,output: 256 x 64 x 64\n",
    "        x5 = self.layer5(x5)\n",
    "        \n",
    "        # input: 256 x 64 x 64,output: 256 x 128 x 128\n",
    "        x6  = self.upsample(x5)\n",
    "        # 拼接,output: 384 x 128 x 128\n",
    "        x6 = torch.cat([x6,x2],dim=1)\n",
    "        # input: 384 x 128 x 128, output: 128 x 128 x 128\n",
    "        x6 = self.layer6(x6)\n",
    "        \n",
    "        \n",
    "        # input:128 x 128 x 128, output: 128 x 256 x 256\n",
    "        x7 = self.upsample(x6)\n",
    "        # 拼接, output: 192 x 256 x256\n",
    "        x7 = torch.cat([x7,x1],dim=1)\n",
    "        # input: 192 x 256 x256, output: 64 x 256 x 256\n",
    "        x7 = self.layer7(x7)\n",
    "        \n",
    "        # 最后一次卷积,input: 64 x 256 x 256, output: 1 x 256 x 256\n",
    "        x8 = self.layer8(x7)\n",
    "        \n",
    "        #sigmoid\n",
    "        # x9= self.sigmoid(x8)\n",
    "        \n",
    "        \n",
    "        \n",
    "        return x8\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632fd43a-e996-4cd7-81b6-3e13ee14a44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实例化\n",
    "model = UNet().to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b4372b-8d9c-4f84-8cc9-c3908a116d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 恢复权重\n",
    "model.load_state_dict(torch.load('saved_model/back_up/unet_best_bce.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aca75a0-e4f6-4298-8a61-5ba50c7a188d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09545a16-a4ea-4776-a5a7-4ebe5ce8f139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe695d51-fff6-4928-9c0b-b72da53e12d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "# 数据增强相关包\n",
    "import imgaug as ia\n",
    "import imgaug.augmenters as iaa\n",
    "from imgaug.augmentables.segmaps import SegmentationMapsOnImage\n",
    "\n",
    "from natsort import natsorted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f7fb45-d096-4dad-b8dd-75859e64d2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegmentDataset(Dataset):\n",
    "    def __init__(self,where='train',seq=None):\n",
    "        # 获取numpy文件数据\n",
    "        # 图片列表\n",
    "        self.img_list =natsorted( glob.glob('processed/{}/*/img_*'.format(where)) )\n",
    "        # self.mask_list = glob.glob('processed/{}/*/label_*'.format(where))\n",
    "        # 数据增强的处理流程\n",
    "        self.seq = seq\n",
    "        \n",
    "    def __len__(self):\n",
    "        # 获取数据集大小\n",
    "        return len(self.img_list)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        # 获取具体某一个数据\n",
    "        \n",
    "        # 获取图片文件名\n",
    "        img_file = self.img_list[idx]\n",
    "        # 获取标注文件名\n",
    "        mask_file = img_file.replace('img','label')\n",
    "        \n",
    "        # 加载数据\n",
    "        img = np.load(img_file)\n",
    "        mask = np.load(mask_file)\n",
    "        \n",
    "        # 数据增强处理\n",
    "        if self.seq:\n",
    "            segmap = SegmentationMapsOnImage(mask,shape=mask.shape)\n",
    "            img,mask = self.seq(image=img, segmentation_maps=segmap)\n",
    "            # 获取数组内容\n",
    "            mask = mask.get_arr()\n",
    "\n",
    "            \n",
    "        # 扩张维度变成张量\n",
    "        return np.expand_dims(img,0),np.expand_dims(mask,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eece77f-22d4-4f69-9c93-3ca1df0edd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用dataloader加载数据\n",
    "batch_size = 12\n",
    "num_workers = 0\n",
    "\n",
    "test_dataset = SegmentDataset('test',None)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,batch_size=batch_size,num_workers=num_workers,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6813a9d6-9107-4d34-8026-b855ff5afd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99531b8-f535-4c2b-8d9f-8fe3ec32f040",
   "metadata": {},
   "outputs": [],
   "source": [
    "#将画面合成为动画\n",
    "from celluloid  import Camera\n",
    "from IPython.display import HTML\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5f9c82-7461-4d0c-a19d-5cd0fa8ce8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#遍历每一层图像和mask\n",
    "fig = plt.figure()\n",
    "camera = Camera(fig)\n",
    "\n",
    "# 遍历所有数据\n",
    "for x,y in tqdm.tqdm(test_dataset):\n",
    "    \n",
    "    # 处理输入\n",
    "    input = torch.tensor([x]).to('cuda:0',dtype=torch.float32)\n",
    "    # 推理\n",
    "    y_pred = model(input)\n",
    "    \n",
    "    # 获取对应的mask（筛选阈值0.5）\n",
    "    mask_data = (y_pred.detach().cpu().numpy()[0][0] > 0.5)\n",
    "    \n",
    "    # 作比对，左侧显示标注，右侧显示实际推理\n",
    "    plt.subplot(1,2,1)\n",
    "    # 显示图片\n",
    "    plt.imshow(x[0],cmap='bone')\n",
    "    \n",
    "    mask = np.ma.masked_where(y[0]==0,y[0])\n",
    "    plt.imshow(mask,alpha=0.8,cmap='spring')\n",
    "    plt.title('Label GD')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    \n",
    "    plt.subplot(1,2,2)\n",
    "    # 显示图片\n",
    "    plt.imshow(x[0],cmap='bone')\n",
    "    \n",
    "    mask = np.ma.masked_where(mask_data==False,mask_data)\n",
    "    plt.imshow(mask,alpha=0.8,cmap='spring')\n",
    "    plt.title('prediction ')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    camera.snap()\n",
    "    # break\n",
    "animation = camera.animate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1392307f-848e-49b1-ad55-b6d725f7e21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(animation.to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15de1235-1423-4e42-a883-0bf6d2ee19e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4ae20a-3366-4d16-9d4f-5987dec7256f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6906be-a90d-4a1a-a1ac-eb0bd496ef75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试未知图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c3dc51-1fbf-4703-b07e-4ba3def492c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os \n",
    "import nibabel as nib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f98005e-f38c-4e00-aec8-e0e4c0b86eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file_list = glob.glob('data/imagesTs/la*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a076d0-7a32-4ada-ac1e-94f158cb63b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7ad7cb-09af-4727-b824-5f82ff532bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将数据同样进行归一化和标准化处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3222df1a-a9b1-4ae0-a605-c390de06d090",
   "metadata": {},
   "outputs": [],
   "source": [
    "#标准化\n",
    "def standardize(data):\n",
    "    # 计算均值\n",
    "    mean = data.mean()\n",
    "    # 计算标准差\n",
    "    std = np.std(data)\n",
    "    \n",
    "    # 计算结果\n",
    "    standardized = (data - mean) / std\n",
    "    return standardized\n",
    "\n",
    "\n",
    "#  归一化\n",
    "def normalize(data):\n",
    "    # 计算最大值和最小值\n",
    "    max_val = data.max()\n",
    "    min_val = data.min()\n",
    "    normalized = (data - min_val) / (max_val - min_val)\n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54335fd5-c515-4379-8a86-d28ea7dd143a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 挑选一个文件测试一下\n",
    "file = test_file_list[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900fbc41-6c49-4ebc-9387-511613ae80b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取\n",
    "img = nib.load(file)\n",
    "img_data = img.get_fdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ac662a-994d-4e8b-b4e5-b6f2a2b674b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bcdcba-6152-4540-a77a-3c863e70ad22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 边缘裁剪\n",
    "img_data_crop = img_data[32:-32,32:-32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0eda214-6d3c-4150-a44c-4b58f6526bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_data_crop.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0579b24a-b89c-4847-a494-9511213562a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 标准化归一化\n",
    "std = standardize(img_data_crop)\n",
    "normalized = normalize(std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de89d611-eacc-4de7-88b7-ac8f80772a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized.max(),normalized.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9627fdfe-4796-43e4-b843-6116d5f7bc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将每一层画面进行推理，并合成动画"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62712e4-d025-4362-b1f7-26eb3f828707",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_num  = normalized.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a754920-9738-4907-987e-1b13d0da5d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05dc413e-a634-4839-a034-1be229cca124",
   "metadata": {},
   "outputs": [],
   "source": [
    "#遍历每一层图像和mask\n",
    "fig = plt.figure()\n",
    "camera = Camera(fig)\n",
    "\n",
    "# 遍历每一层\n",
    "for i in tqdm.tqdm(range(layer_num)):\n",
    "    # 获取该层画面\n",
    "    layer = normalized[:,:,i]\n",
    "    \n",
    "    # 处理输入\n",
    "    input = torch.tensor([[layer]]).to('cuda:0',dtype=torch.float32)\n",
    "    # 推理\n",
    "    y_pred = model(input)\n",
    "    \n",
    "    # 获取对应的mask（筛选阈值0.5）\n",
    "    mask_data = (y_pred.detach().cpu().numpy()[0][0] > 0.5)\n",
    "    \n",
    "    # 将mask和图片绘制在一起\n",
    "    img_display = np.rot90(layer)\n",
    "    mask_display = np.rot90(mask_data)   \n",
    "    # 将mask_display像素值为0处遮挡起来\n",
    "    mask = np.ma.masked_where(mask_display==0,mask_display)\n",
    "    plt.imshow(img_display,cmap='bone')\n",
    "    plt.imshow(mask,alpha=0.8,cmap='spring')\n",
    "    # break\n",
    "    plt.axis('off')\n",
    "    \n",
    "    camera.snap()\n",
    "    \n",
    "animation = camera.animate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8741f137-5a8f-4abb-bd8c-fdc4a007edfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(animation.to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdcb68a-d371-43c4-aaea-f940e2a1332c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7563fd53-de44-4a40-a631-389b2ae6d9a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6322d00a-f68f-4f84-89a3-7cc27c5fd757",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
